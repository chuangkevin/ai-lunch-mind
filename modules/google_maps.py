"""
Google Maps é¤å»³æœå°‹æ¨¡çµ„ - Selenium ç‰ˆæœ¬ + å¤šå·¥è™•ç†å„ªåŒ–
ä½¿ç”¨ Selenium é€²è¡ŒçœŸå¯¦ç€è¦½å™¨è‡ªå‹•åŒ–æœå°‹ï¼Œæä¾›æ›´æº–ç¢ºçš„é¤å»³è³‡è¨Š
æ–°å¢å¤šå·¥è™•ç†åŠŸèƒ½ï¼šä¸¦è¡Œæœå°‹ã€ç€è¦½å™¨æ± ã€å¿«å–æ©Ÿåˆ¶
"""

from typing import List, Dict, Optional, Any, Tuple
import time
import random
import re
import requests
import urllib.parse
from urllib.parse import quote, unquote, parse_qs, urlparse
import ssl
import urllib3
from bs4 import BeautifulSoup
from geopy.distance import geodesic
from geopy.geocoders import Nominatim
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import logging
import asyncio
import concurrent.futures
import threading
from queue import Queue
from contextlib import contextmanager
import json
from datetime import datetime, timedelta

# ç¦ç”¨ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# TODO: å°‡ User-Agent æ¸…å–®æ”¹ç”¨è³‡æ–™åº«å­˜å„² (å¦‚ SQLite)
# å»ºè­°è³‡æ–™è¡¨ï¼šuser_agents (id, agent_string, browser_type, active_status, last_used)
# å„ªé»ï¼šæ”¯æ´å‹•æ…‹æ›´æ–°ã€ä½¿ç”¨é »ç‡è¿½è¹¤ã€å¤±æ•ˆæª¢æ¸¬ã€ç€è¦½å™¨é¡å‹åˆ†é¡
# User-Agent æ± ï¼Œç”¨æ–¼é™ä½è¢«åµæ¸¬æ©Ÿç‡
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/120.0',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15'
]

def create_session() -> requests.Session:
    """
    å»ºç«‹æ¨¡æ“¬ç€è¦½å™¨çš„ Sessionï¼ˆå‚™ç”¨æ–¹æ¡ˆï¼‰
    :return: é…ç½®å¥½çš„ requests.Session
    """
    session = requests.Session()
    
    # éš¨æ©Ÿé¸æ“‡ User-Agent
    headers = {
        'User-Agent': random.choice(USER_AGENTS),
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'zh-TW,zh;q=0.9,en;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
    }
    session.headers.update(headers)
    
    # å¿½ç•¥ SSL é©—è­‰
    session.verify = False
    
    return session

def create_chrome_driver(headless: bool = True) -> webdriver.Chrome:
    """
    å»ºç«‹ Chrome ç€è¦½å™¨é©…å‹•
    :param headless: æ˜¯å¦ç„¡é ­æ¨¡å¼
    :return: Chrome WebDriver
    """
    options = Options()
    
    if headless:
        options.add_argument('--headless')
    
    # åŸºæœ¬è¨­å®š
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-gpu')
    options.add_argument('--disable-gpu-sandbox')
    options.add_argument('--disable-software-rasterizer')
    options.add_argument('--disable-background-timer-throttling')
    options.add_argument('--disable-backgrounding-occluded-windows')
    options.add_argument('--disable-renderer-backgrounding')
    options.add_argument('--disable-features=TranslateUI')
    options.add_argument('--disable-ipc-flooding-protection')
    options.add_argument('--disable-web-security')
    options.add_argument('--disable-features=VizDisplayCompositor')
    options.add_argument('--window-size=1920,1080')
    options.add_argument('--disable-blink-features=AutomationControlled')
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option('useAutomationExtension', False)
    
    # é¡å¤–çš„æ—¥èªŒæŠ‘åˆ¶è¨­å®š
    options.add_experimental_option("excludeSwitches", ["enable-logging"])
    options.add_experimental_option('useAutomationExtension', False)
    options.add_argument('--disable-logging')
    options.add_argument('--disable-gpu-logging')
    options.add_argument('--silent')
    options.add_argument('--log-level=3')
    
    # éš¨æ©Ÿ User-Agent
    user_agent = random.choice(USER_AGENTS)
    options.add_argument(f'--user-agent={user_agent}')
    
    # èªè¨€è¨­å®š
    options.add_argument('--lang=zh-TW')
    
    try:
        driver = webdriver.Chrome(options=options)
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        return driver
    except Exception as e:
        logger.error(f"å»ºç«‹ Chrome é©…å‹•å¤±æ•—: {e}")
        raise

def create_chrome_driver_fast(headless: bool = True) -> webdriver.Chrome:
    """
    å»ºç«‹ Chrome ç€è¦½å™¨é©…å‹• - é€Ÿåº¦å„ªåŒ–ç‰ˆæœ¬
    :param headless: æ˜¯å¦ç„¡é ­æ¨¡å¼
    :return: Chrome WebDriver
    """
    options = Options()
    
    if headless:
        options.add_argument('--headless')
    
    # æœ€ç²¾ç°¡çš„è¨­å®š - åªä¿ç•™å¿…è¦é¸é …
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-gpu')
    options.add_argument('--disable-logging')
    options.add_argument('--disable-extensions')
    options.add_argument('--disable-plugins')
    options.add_argument('--disable-images')  # ä¸è¼‰å…¥åœ–ç‰‡åŠ é€Ÿ
    options.add_argument('--disable-javascript')  # ä¸åŸ·è¡Œ JS åŠ é€Ÿ
    options.add_argument('--window-size=1024,768')  # å°è¦–çª—
    
    # æœ€å¿«çš„ User-Agent
    options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
    
    try:
        driver = webdriver.Chrome(options=options)
        return driver
    except Exception as e:
        logger.error(f"å»ºç«‹å¿«é€Ÿ Chrome é©…å‹•å¤±æ•—: {e}")
        raise

class BrowserPool:
    """ç€è¦½å™¨å¯¦ä¾‹æ± ï¼Œç®¡ç†å¤šå€‹ç€è¦½å™¨å¯¦ä¾‹ä»¥æå‡æ•ˆèƒ½"""
    
    def __init__(self, pool_size: int = 1):  # æ¸›å°‘æ± å¤§å°
        self.pool_size = pool_size
        self.available_browsers = Queue()
        self.all_browsers = []
        self.lock = threading.Lock()
        self._initialize_pool()
    
    def _initialize_pool(self):
        """åˆå§‹åŒ–ç€è¦½å™¨æ± """
        logger.info(f"ğŸš€ åˆå§‹åŒ–ç€è¦½å™¨æ± ï¼Œå¤§å°: {self.pool_size}")
        for i in range(self.pool_size):
            try:
                driver = create_chrome_driver_fast()  # ä½¿ç”¨å¿«é€Ÿç‰ˆæœ¬
                self.available_browsers.put(driver)
                self.all_browsers.append(driver)
                logger.info(f"âœ… ç€è¦½å™¨ {i+1} å·²å‰µå»ºä¸¦åŠ å…¥æ± ä¸­")
            except Exception as e:
                logger.error(f"âŒ å‰µå»ºç€è¦½å™¨ {i+1} å¤±æ•—: {e}")
    
    @contextmanager
    def get_browser(self):
        """ç²å–ç€è¦½å™¨å¯¦ä¾‹çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        driver = None
        try:
            # å˜—è©¦å¾æ± ä¸­ç²å–ç€è¦½å™¨ï¼Œè¶…æ™‚ 3 ç§’
            driver = self.available_browsers.get(timeout=3)
            yield driver
        except:
            # å¦‚æœæ± ä¸­æ²’æœ‰å¯ç”¨ç€è¦½å™¨ï¼Œå‰µå»ºæ–°çš„
            logger.warning("âš ï¸ æ± ä¸­ç„¡å¯ç”¨ç€è¦½å™¨ï¼Œå‰µå»ºæ–°å¯¦ä¾‹")
            driver = create_chrome_driver(headless=True)
            yield driver
        finally:
            if driver:
                try:
                    # æ¸…ç†ç€è¦½å™¨ç‹€æ…‹
                    driver.delete_all_cookies()
                    # å°‡ç€è¦½å™¨æ”¾å›æ± ä¸­
                    self.available_browsers.put(driver)
                except:
                    # å¦‚æœç€è¦½å™¨å·²æå£ï¼Œé—œé–‰å®ƒ
                    try:
                        driver.quit()
                    except:
                        pass
    
    def close_all(self):
        """é—œé–‰æ‰€æœ‰ç€è¦½å™¨å¯¦ä¾‹"""
        logger.info("ğŸ›‘ é—œé–‰æ‰€æœ‰ç€è¦½å™¨å¯¦ä¾‹")
        for driver in self.all_browsers:
            try:
                driver.quit()
            except:
                pass

class SearchCache:
    """æœå°‹çµæœå¿«å–ï¼Œé¿å…é‡è¤‡æœå°‹"""
    
    def __init__(self, cache_ttl: int = 300):  # 5åˆ†é˜å¿«å–
        self.cache = {}
        self.cache_ttl = cache_ttl
        self.lock = threading.Lock()
    
    def get_cache_key(self, keyword: str, location_info: Optional[Dict] = None) -> str:
        """ç”Ÿæˆå¿«å–éµ"""
        location_str = ""
        if location_info and location_info.get('address'):
            location_str = location_info['address']
        return f"{keyword}_{location_str}"
    
    def get(self, keyword: str, location_info: Optional[Dict] = None) -> Optional[List[Dict]]:
        """ç²å–å¿«å–çµæœ"""
        cache_key = self.get_cache_key(keyword, location_info)
        with self.lock:
            if cache_key in self.cache:
                cached_data, timestamp = self.cache[cache_key]
                if datetime.now() - timestamp < timedelta(seconds=self.cache_ttl):
                    logger.info(f"ğŸ“¦ ä½¿ç”¨å¿«å–çµæœ: {cache_key}")
                    return cached_data
                else:
                    # å¿«å–éæœŸï¼Œåˆªé™¤
                    del self.cache[cache_key]
        return None
    
    def set(self, keyword: str, location_info: Optional[Dict], results: List[Dict]):
        """è¨­ç½®å¿«å–çµæœ"""
        cache_key = self.get_cache_key(keyword, location_info)
        with self.lock:
            self.cache[cache_key] = (results, datetime.now())
            logger.info(f"ğŸ’¾ å¿«å–æœå°‹çµæœ: {cache_key}")

# å…¨åŸŸå¯¦ä¾‹
browser_pool = BrowserPool(pool_size=2)
search_cache = SearchCache()

def expand_short_url(short_url: str, max_redirects: int = 10) -> str:
    """
    å±•é–‹ Google Maps çŸ­ç¶²å€ - æ”¹é€²ç‰ˆæœ¬
    :param short_url: çŸ­ç¶²å€
    :param max_redirects: æœ€å¤§é‡å®šå‘æ¬¡æ•¸
    :return: å®Œæ•´ URL
    """
    try:
        session = create_session()
        
        # è¨­å®šæ›´è©³ç´°çš„è«‹æ±‚é ­
        session.headers.update({
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-TW,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache'
        })
        
        # é€æ­¥è·Ÿè¹¤é‡å®šå‘
        current_url = short_url
        redirect_count = 0
        
        while redirect_count < max_redirects:
            try:
                response = session.get(current_url, allow_redirects=False, timeout=15)
                
                # æª¢æŸ¥æ˜¯å¦æœ‰é‡å®šå‘
                if response.status_code in [301, 302, 303, 307, 308]:
                    location = response.headers.get('Location')
                    if location:
                        if location.startswith('/'):
                            # ç›¸å°è·¯å¾‘ï¼Œéœ€è¦çµ„åˆå®Œæ•´URL
                            from urllib.parse import urljoin
                            current_url = urljoin(current_url, location)
                        else:
                            current_url = location
                        redirect_count += 1
                        logger.info(f"é‡å®šå‘ {redirect_count}: {current_url}")
                        continue
                
                # å¦‚æœæ˜¯æœ€çµ‚URLæˆ–ç„¡é‡å®šå‘
                if response.status_code == 200:
                    final_url = current_url
                    logger.info(f"çŸ­ç¶²å€å±•é–‹æˆåŠŸ: {short_url} -> {final_url}")
                    return final_url
                
                break
                
            except requests.RequestException as e:
                logger.warning(f"é‡å®šå‘è¿½è¹¤å¤±æ•—: {e}")
                break
        
        # å¦‚æœè¿½è¹¤å¤±æ•—ï¼Œå˜—è©¦ç›´æ¥è«‹æ±‚ä¸¦ç²å–æœ€çµ‚URL
        try:
            response = session.get(short_url, allow_redirects=True, timeout=15)
            final_url = response.url
            logger.info(f"ç›´æ¥å±•é–‹æˆåŠŸ: {short_url} -> {final_url}")
            return final_url
        except Exception as e:
            logger.error(f"çŸ­ç¶²å€å±•é–‹å®Œå…¨å¤±æ•—: {e}")
            return short_url
            
    except Exception as e:
        logger.error(f"å±•é–‹çŸ­ç¶²å€å¤±æ•—: {e}")
        return short_url

def extract_location_from_url(url: str) -> Optional[Tuple[float, float, str]]:
    """
    å¾ Google Maps URL æå–ä½ç½®è³‡è¨Š - æ”¹é€²ç‰ˆæœ¬
    :param url: Google Maps URL
    :return: (latitude, longitude, place_name) æˆ– None
    """
    try:
        original_url = url
        
        # å±•é–‹çŸ­ç¶²å€
        if 'maps.app.goo.gl' in url or 'goo.gl' in url or 'g.co/kgs/' in url or len(url) < 50:
            logger.info(f"å±•é–‹çŸ­ç¶²å€: {url}")
            url = expand_short_url(url)
            if url == original_url:
                logger.warning("çŸ­ç¶²å€å±•é–‹å¤±æ•—ï¼Œä½¿ç”¨åŸå§‹URL")
        
        logger.info(f"è™•ç†URL: {url}")
        
        # å¤šç¨®åº§æ¨™æå–æ¨¡å¼
        coordinate_patterns = [
            r'/@(-?\d+\.\d+),(-?\d+\.\d+)',  # æ¨™æº–æ ¼å¼ /@lat,lng
            r'/place/[^/]*/@(-?\d+\.\d+),(-?\d+\.\d+)',  # placeæ ¼å¼
            r'!3d(-?\d+\.\d+)!4d(-?\d+\.\d+)',  # ç·¨ç¢¼æ ¼å¼
            r'center=(-?\d+\.\d+),(-?\d+\.\d+)',  # centeråƒæ•¸
            r'll=(-?\d+\.\d+),(-?\d+\.\d+)',  # llåƒæ•¸
            r'q=(-?\d+\.\d+),(-?\d+\.\d+)',  # qåƒæ•¸åº§æ¨™
        ]
        
        lat, lng = None, None
        for pattern in coordinate_patterns:
            coord_match = re.search(pattern, url)
            if coord_match:
                try:
                    lat = float(coord_match.group(1))
                    lng = float(coord_match.group(2))
                    
                    # é©—è­‰åº§æ¨™æ˜¯å¦åœ¨å°ç£ç¯„åœå…§
                    if 21.0 <= lat <= 26.0 and 119.0 <= lng <= 122.5:
                        logger.info(f"æå–åº§æ¨™æˆåŠŸ: ({lat}, {lng})")
                        break
                    else:
                        logger.warning(f"åº§æ¨™è¶…å‡ºå°ç£ç¯„åœ: ({lat}, {lng})")
                        lat, lng = None, None
                except ValueError:
                    continue
        
        if lat is None or lng is None:
            logger.warning("ç„¡æ³•å¾URLæå–æœ‰æ•ˆåº§æ¨™")
            return None
        
        # æå–åœ°é»åç¨± - å¤šç¨®æ¨¡å¼
        place_name = None
        place_patterns = [
            r'/place/([^/@]+)',  # æ¨™æº–placeæ ¼å¼
            r'search/([^/@]+)',  # searchæ ¼å¼  
            r'q=([^&@]+)',  # qåƒæ•¸
            r'query=([^&@]+)',  # queryåƒæ•¸
        ]
        
        for pattern in place_patterns:
            place_match = re.search(pattern, url)
            if place_match:
                try:
                    raw_name = place_match.group(1)
                    # URLè§£ç¢¼
                    place_name = unquote(raw_name)
                    # æ¸…ç†æ ¼å¼
                    place_name = place_name.replace('+', ' ').replace('%20', ' ')
                    place_name = place_name.strip()
                    
                    # é©—è­‰åœ°é»åç¨±åˆç†æ€§
                    if len(place_name) > 1 and not place_name.isdigit():
                        logger.info(f"æå–åœ°é»åç¨±: {place_name}")
                        break
                    else:
                        place_name = None
                except Exception:
                    continue
        
        if not place_name:
            # å¦‚æœç„¡æ³•æå–åœ°é»åç¨±ï¼Œå˜—è©¦åå‘åœ°ç†ç·¨ç¢¼
            try:
                from geopy.geocoders import Nominatim
                geolocator = Nominatim(user_agent="lunch-recommendation-system")
                location = geolocator.reverse(f"{lat}, {lng}", language='zh-TW')
                if location and location.address:
                    place_name = location.address.split(',')[0]  # å–ç¬¬ä¸€éƒ¨åˆ†ä½œç‚ºåœ°é»åç¨±
                    logger.info(f"åå‘åœ°ç†ç·¨ç¢¼ç²å¾—åœ°é»åç¨±: {place_name}")
            except Exception as e:
                logger.warning(f"åå‘åœ°ç†ç·¨ç¢¼å¤±æ•—: {e}")
                place_name = f"ä½ç½® ({lat:.4f}, {lng:.4f})"
        
        return (lat, lng, place_name)
        
    except Exception as e:
        logger.error(f"URL ä½ç½®æå–å¤±æ•—: {e}")
        return None

def normalize_taiwan_address(address: str) -> str:
    """
    æ¨™æº–åŒ–å°ç£åœ°å€æ ¼å¼
    :param address: åŸå§‹åœ°å€
    :return: æ¨™æº–åŒ–å¾Œçš„åœ°å€
    """
    if not address:
        return ""
    
    # ç§»é™¤å¤šé¤˜ç©ºç™½å’Œç‰¹æ®Šå­—ç¬¦
    address = re.sub(r'\s+', '', address)
    
    # è£œå…¨å¸¸è¦‹ç¸®å¯« - æ³¨æ„ä¸è¦å½±éŸ¿ç¾æœ‰çš„å®Œæ•´åç¨±
    address_replacements = {
        'åŒ—å¸‚': 'å°åŒ—å¸‚',
        'æ¡ƒå¸‚': 'æ¡ƒåœ’å¸‚', 
        'é«˜å¸‚': 'é«˜é›„å¸‚'
    }
    
    for old, new in address_replacements.items():
        # åªæœ‰ç•¶ä¸å­˜åœ¨å®Œæ•´åç¨±æ™‚æ‰æ›¿æ›ç¸®å¯«
        if old in address and new not in address:
            address = address.replace(old, new)
    
    # ç¢ºä¿åœ°å€åŒ…å«å®Œæ•´çš„è¡Œæ”¿å€åŠƒ
    if 'å°åŒ—å¸‚' in address and 'å€' not in address and 'é„‰' not in address and 'é®' not in address:
        # å˜—è©¦å¾å¸¸è¦‹å€åŸŸåç¨±æ¨æ–·å°åŒ—å¸‚çš„å€
        district_mapping = {
            'ä¸­å±±': 'ä¸­å±±å€',
            'ä¿¡ç¾©': 'ä¿¡ç¾©å€',
            'å¤§å®‰': 'å¤§å®‰å€',
            'æ¾å±±': 'æ¾å±±å€',
            'ä¸­æ­£': 'ä¸­æ­£å€',
            'è¬è¯': 'è¬è¯å€',
            'å¤§åŒ': 'å¤§åŒå€',
            'å£«æ—': 'å£«æ—å€',
            'åŒ—æŠ•': 'åŒ—æŠ•å€',
            'å…§æ¹–': 'å…§æ¹–å€',
            'å—æ¸¯': 'å—æ¸¯å€',
            'æ–‡å±±': 'æ–‡å±±å€'
        }
        
        for district, full_district in district_mapping.items():
            if district in address and full_district not in address:
                address = address.replace(f'å°åŒ—å¸‚{district}', f'å°åŒ—å¸‚{full_district}')
                break
    
    return address

def geocode_address(address: str) -> Optional[Tuple[float, float]]:
    """
    å°‡åœ°å€è½‰æ›ç‚ºåº§æ¨™ - æ”¹é€²ç‰ˆæœ¬ï¼Œæ”¯æ´å¤šé‡åœ°ç†ç·¨ç¢¼æœå‹™
    :param address: åœ°å€å­—ä¸²
    :return: (latitude, longitude) æˆ– None
    """
    if not address or len(address.strip()) < 3:
        return None
    
    # æ¨™æº–åŒ–åœ°å€
    normalized_address = normalize_taiwan_address(address)
    logger.info(f"æ¨™æº–åŒ–åœ°å€: {address} -> {normalized_address}")
    
    # å˜—è©¦å¤šç¨®åœ°å€æ ¼å¼
    address_variants = [
        normalized_address + ", Taiwan",
        normalized_address + ", å°ç£",
        normalized_address,
        address + ", Taiwan",  # åŸå§‹åœ°å€
        address.replace('å°', 'è‡º') + ", Taiwan"  # å°/è‡ºè½‰æ› - åªåœ¨ä¸åŒ…å« "å°åŒ—" "å°ä¸­" "å°å—" ç­‰åŸå¸‚åæ™‚è½‰æ›
    ]
    
    # æ–¹æ³•1: ä½¿ç”¨ Nominatim (OpenStreetMap)
    try:
        geolocator = Nominatim(user_agent="lunch-recommendation-system", timeout=10)
        for addr_variant in address_variants:
            try:
                location = geolocator.geocode(addr_variant)
                if location and location.latitude and location.longitude:
                    # æª¢æŸ¥åº§æ¨™æ˜¯å¦åœ¨å°ç£ç¯„åœå…§
                    if 21.0 <= location.latitude <= 26.0 and 119.0 <= location.longitude <= 122.5:
                        logger.info(f"Nominatim æˆåŠŸè§£æåœ°å€: {addr_variant} -> ({location.latitude}, {location.longitude})")
                        return (location.latitude, location.longitude)
            except Exception as e:
                logger.warning(f"Nominatim è§£æå¤±æ•—: {addr_variant} - {e}")
                continue
    except Exception as e:
        logger.error(f"Nominatim æœå‹™å¤±æ•—: {e}")
    
    # æ–¹æ³•2: ä½¿ç”¨åº§æ¨™æå– (å¦‚æœåœ°å€ä¸­åŒ…å«åº§æ¨™è³‡è¨Š)
    try:
        coord_match = re.search(r'(\d{2}\.\d+)[,\s]+(\d{2,3}\.\d+)', address)
        if coord_match:
            lat = float(coord_match.group(1))
            lng = float(coord_match.group(2))
            if 21.0 <= lat <= 26.0 and 119.0 <= lng <= 122.5:
                logger.info(f"å¾åœ°å€ä¸­æå–åº§æ¨™: ({lat}, {lng})")
                return (lat, lng)
    except Exception:
        pass
    
    # æ–¹æ³•3: å˜—è©¦ Google Maps API æ ¼å¼è§£æ (å‚™ç”¨)
    try:
        # å¦‚æœåœ°å€çœ‹èµ·ä¾†åƒæ˜¯å¾ Google Maps è¤‡è£½çš„æ ¼å¼
        if 'è™Ÿ' in address or ('è·¯' in address and ('æ®µ' in address or 'å··' in address)):
            # å˜—è©¦æ›´ç°¡åŒ–çš„æŸ¥è©¢
            simplified_parts = []
            
            # æå–å¸‚/ç¸£
            city_match = re.search(r'([\u4e00-\u9fff]+[å¸‚ç¸£])', address)
            if city_match:
                simplified_parts.append(city_match.group(1))
            
            # æå–å€/é„‰/é®
            district_match = re.search(r'([\u4e00-\u9fff]+[å€é„‰é®å¸‚])', address)
            if district_match:
                simplified_parts.append(district_match.group(1))
            
            # æå–ä¸»è¦é“è·¯
            road_match = re.search(r'([\u4e00-\u9fff]+[è·¯è¡—å¤§é“])', address)
            if road_match:
                simplified_parts.append(road_match.group(1))
            
            if simplified_parts:
                simplified_address = ''.join(simplified_parts) + ", Taiwan"
                geolocator = Nominatim(user_agent="lunch-recommendation-system", timeout=10)
                location = geolocator.geocode(simplified_address)
                if location and 21.0 <= location.latitude <= 26.0 and 119.0 <= location.longitude <= 122.5:
                    logger.info(f"ç°¡åŒ–åœ°å€è§£ææˆåŠŸ: {simplified_address} -> ({location.latitude}, {location.longitude})")
                    return (location.latitude, location.longitude)
    
    except Exception as e:
        logger.warning(f"ç°¡åŒ–åœ°å€è§£æå¤±æ•—: {e}")
    
    logger.warning(f"åœ°å€è§£æå¤±æ•—: {address}")
    return None

def validate_and_select_best_address(addresses: List[str]) -> Optional[str]:
    """
    é©—è­‰åœ°å€åˆ—è¡¨ä¸¦é¸æ“‡æœ€ä½³åœ°å€ - é‡é»é—œæ³¨å®Œæ•´æ€§
    :param addresses: åœ°å€å€™é¸åˆ—è¡¨
    :return: æœ€ä½³åœ°å€æˆ– None
    """
    if not addresses:
        return None
    
    # åœ°å€è©•åˆ†å‡½æ•¸ - é‡æ–°è¨­è¨ˆï¼Œæ›´æ³¨é‡å®Œæ•´æ€§
    def score_address(addr: str) -> int:
        score = 0
        addr = addr.strip()
        
        # åŸºç¤é•·åº¦è©•åˆ†
        if 12 <= len(addr) <= 60:
            score += 15  # å¢åŠ å°åˆç†é•·åº¦çš„çå‹µ
        elif 8 <= len(addr) <= 80:
            score += 8
        
        # å®Œæ•´æ€§è©•åˆ† - æé«˜æ¬Šé‡
        has_city = any(keyword in addr for keyword in ['å¸‚', 'ç¸£'])
        has_district = any(keyword in addr for keyword in ['å€', 'é„‰', 'é®'])
        has_road = any(keyword in addr for keyword in ['è·¯', 'è¡—', 'å¤§é“', 'å··', 'å¼„'])
        has_number = bool(re.search(r'\d+è™Ÿ', addr))
        has_postal = bool(re.match(r'^\d{3}', addr))
        
        if has_city:
            score += 20  # æé«˜å¸‚/ç¸£çš„æ¬Šé‡
        if has_district:
            score += 20  # æé«˜å€çš„æ¬Šé‡
        if has_road:
            score += 15  # è·¯åå¾ˆé‡è¦
        if has_number:
            score += 12  # é–€ç‰Œè™Ÿç¢¼å¾ˆé‡è¦
        if has_postal:
            score += 8   # éƒµéå€è™ŸåŠ åˆ†
        
        # è©³ç´°è³‡è¨ŠåŠ åˆ†
        if 'æ®µ' in addr:
            score += 5
        if 'å··' in addr:
            score += 4
        if 'å¼„' in addr:
            score += 3
        if 'æ¨“' in addr:
            score += 2
        
        # å®Œæ•´æ€§æª¢æŸ¥ - é‡è¦çš„è©•åˆ†é …ç›®
        completeness_count = sum([has_city, has_district, has_road, has_number])
        if completeness_count >= 4:
            score += 25  # éå¸¸å®Œæ•´çš„åœ°å€
        elif completeness_count >= 3:
            score += 15  # è¼ƒå®Œæ•´çš„åœ°å€
        elif completeness_count >= 2:
            score += 5   # åŸºæœ¬å®Œæ•´
        
        # æ‡²ç½°æ˜é¡¯éŒ¯èª¤çš„æ ¼å¼
        if re.search(r'[a-zA-Z]{5,}', addr):  # åŒ…å«å¤ªå¤šè‹±æ–‡
            score -= 15
        if len(addr) < 6:  # å¤ªçŸ­
            score -= 20
        if 'é›»è©±' in addr or 'è©•åˆ†' in addr or 'ç‡Ÿæ¥­æ™‚é–“' in addr:  # åŒ…å«éåœ°å€è³‡è¨Š
            score -= 25
        if 'å…¬é‡Œ' in addr or 'åˆ†é˜' in addr or 'å°æ™‚' in addr:  # æ™‚é–“è·é›¢è³‡è¨Š
            score -= 20
        
        return score
    
    # å°æ‰€æœ‰åœ°å€è©•åˆ†ä¸¦æ’åº
    scored_addresses = [(addr, score_address(addr)) for addr in addresses]
    scored_addresses.sort(key=lambda x: x[1], reverse=True)
    
    # è¨˜éŒ„æ‰€æœ‰å€™é¸åœ°å€çš„è©•åˆ†ï¼ˆç”¨æ–¼èª¿è©¦ï¼‰
    logger.debug("åœ°å€å€™é¸åˆ—è¡¨è©•åˆ†:")
    for addr, score in scored_addresses[:5]:  # åªé¡¯ç¤ºå‰5å€‹
        logger.debug(f"  {addr[:30]}... -> è©•åˆ†: {score}")
    
    # è¿”å›è©•åˆ†æœ€é«˜ä¸”åˆ†æ•¸ > 10 çš„åœ°å€ï¼ˆæé«˜é–€æª»ï¼‰
    if scored_addresses and scored_addresses[0][1] > 10:
        best_address = scored_addresses[0][0].strip()
        logger.info(f"é¸æ“‡æœ€ä½³åœ°å€: {best_address} (è©•åˆ†: {scored_addresses[0][1]})")
        return best_address
    
    return None

def is_valid_taiwan_address(address: str) -> bool:
    """
    æª¢æŸ¥æ˜¯å¦ç‚ºæœ‰æ•ˆçš„å°ç£åœ°å€
    :param address: åœ°å€å­—ä¸²
    :return: æ˜¯å¦æœ‰æ•ˆ
    """
    if not address or len(address.strip()) < 3:
        return False
    
    address = address.strip()
    
    # å¿…é ˆåŒ…å«å°ç£åœ°å€çš„åŸºæœ¬å…ƒç´ 
    has_city = any(keyword in address for keyword in ['å¸‚', 'ç¸£'])
    has_district = any(keyword in address for keyword in ['å€', 'é„‰', 'é®'])
    has_road = any(keyword in address for keyword in ['è·¯', 'è¡—', 'å¤§é“', 'å··', 'å¼„'])
    
    # è‡³å°‘è¦æœ‰å¸‚/ç¸£ + (å€/é„‰/é® æˆ– è·¯/è¡—) æˆ–è€… å€ + è·¯
    if has_city and (has_district or has_road):
        return True
    
    # æˆ–è€…åªæœ‰å€å’Œè·¯ä¹Ÿå¯ä»¥æ¥å—ï¼ˆå¦‚ "ä¸­å±±å€æ°‘æ¬Šæ±è·¯"ï¼‰
    if has_district and has_road:
        return True
    
    # æˆ–è€…åŒ…å«éƒµéå€è™Ÿ
    if re.match(r'^\d{3}', address) and (has_city or has_district or has_road):
        return True
    
    # æ’é™¤æ˜é¡¯éåœ°å€çš„å…§å®¹
    exclude_keywords = ['é›»è©±', 'è©•åˆ†', 'ç‡Ÿæ¥­æ™‚é–“', 'å…¬é‡Œ', 'åˆ†é˜', 'æ˜ŸæœŸ', 'å°æ™‚', 'ç¶²ç«™', 'http']
    if any(keyword in address for keyword in exclude_keywords):
        return False
    
    return False

def clean_address(address: str) -> str:
    """
    æ¸…ç†åœ°å€æ ¼å¼
    :param address: åŸå§‹åœ°å€
    :return: æ¸…ç†å¾Œçš„åœ°å€
    """
    if not address:
        return ""
    
    # ç§»é™¤å‰å¾Œç©ºç™½
    address = address.strip()
    
    # ç§»é™¤å¸¸è¦‹çš„éåœ°å€å‰ç¶´
    prefixes_to_remove = ['åœ°å€:', 'åœ°å€ï¼š', 'ä½æ–¼:', 'ä½æ–¼ï¼š', 'åœ°é»:', 'åœ°é»ï¼š']
    for prefix in prefixes_to_remove:
        if address.startswith(prefix):
            address = address[len(prefix):].strip()
    
    # ç§»é™¤å¸¸è¦‹çš„å¾Œç¶´è³‡è¨Š
    suffixes_to_remove = ['(', 'ï¼ˆ', 'Â·', 'â€¢', 'é›»è©±', 'è©•åˆ†', 'ç‡Ÿæ¥­æ™‚é–“']
    for suffix in suffixes_to_remove:
        if suffix in address:
            address = address.split(suffix)[0].strip()
    
    # ç§»é™¤å¤šé¤˜çš„ç©ºç™½å­—ç¬¦
    address = re.sub(r'\s+', ' ', address)
    
    return address

def is_complete_address(address: str) -> bool:
    """
    æª¢æŸ¥åœ°å€æ˜¯å¦è¶³å¤ å®Œæ•´
    :param address: åœ°å€å­—ä¸²
    :return: æ˜¯å¦å®Œæ•´
    """
    if not address or len(address.strip()) < 8:
        return False
    
    address = address.strip()
    
    # æª¢æŸ¥æ˜¯å¦åŒ…å«å®Œæ•´åœ°å€è¦ç´ 
    has_city = any(keyword in address for keyword in ['å¸‚', 'ç¸£'])
    has_district = any(keyword in address for keyword in ['å€', 'é„‰', 'é®'])
    has_road = any(keyword in address for keyword in ['è·¯', 'è¡—', 'å¤§é“', 'å··', 'å¼„'])
    has_number = bool(re.search(r'\d+è™Ÿ', address))
    
    # è‡³å°‘éœ€è¦ 3 å€‹è¦ç´ ä¸”å¿…é ˆåŒ…å«é–€ç‰Œè™Ÿæ‰ç®—å®Œæ•´
    completeness_score = sum([has_city, has_district, has_road, has_number])
    
    # å¦‚æœæœ‰éƒµéå€è™Ÿï¼Œå¯ä»¥ç¨å¾®é™ä½è¦æ±‚ï¼Œä½†ä»éœ€è¦é–€ç‰Œè™Ÿ
    has_postal = bool(re.match(r'^\d{3}', address))
    if has_postal:
        return completeness_score >= 3 and has_number
    
    # ä¸€èˆ¬æƒ…æ³ä¸‹ï¼Œéœ€è¦4å€‹è¦ç´ éƒ½æœ‰æˆ–è‡³å°‘3å€‹ä¸”åŒ…å«é–€ç‰Œè™Ÿ
    return (completeness_score >= 4) or (completeness_score >= 3 and has_number)

def extract_address_from_maps_url(maps_url: str) -> Optional[str]:
    """
    å¾ Google Maps URL å˜—è©¦æå–å®Œæ•´åœ°å€
    :param maps_url: Google Maps URL
    :return: æå–çš„åœ°å€æˆ– None
    """
    try:
        # å¦‚æœæ˜¯çŸ­ç¶²å€ï¼Œå…ˆå±•é–‹
        if 'goo.gl' in maps_url or len(maps_url) < 50:
            maps_url = expand_short_url(maps_url)
        
        # å¾ URL ä¸­çš„ place éƒ¨åˆ†æå–åœ°å€
        place_match = re.search(r'/place/([^/@]+)', maps_url)
        if place_match:
            encoded_place = place_match.group(1)
            decoded_place = unquote(encoded_place).replace('+', ' ')
            
            # æª¢æŸ¥æ˜¯å¦åƒåœ°å€
            if is_valid_taiwan_address(decoded_place):
                cleaned = clean_address(decoded_place)
                if is_complete_address(cleaned):
                    return cleaned
        
        # å˜—è©¦ä½¿ç”¨ Selenium ç²å–é é¢ä¸Šçš„åœ°å€
        try:
            driver = create_chrome_driver(headless=True)
            driver.get(maps_url)
            time.sleep(3)
            
            # åœ¨ Google Maps é é¢å°‹æ‰¾åœ°å€
            address_selectors = [
                "button[data-item-id='address']",
                "div[data-attrid='kc:/location/location:address']",
                "span[data-attrid='kc:/location/location:address']",
                ".QSFF4-text",
                ".Io6YTe",
                "div.rogA2c",
                "button.CsEnBe"
            ]
            
            for selector in address_selectors:
                try:
                    elements = driver.find_elements(By.CSS_SELECTOR, selector)
                    for elem in elements:
                        text = elem.text.strip()
                        if is_valid_taiwan_address(text) and is_complete_address(text):
                            driver.quit()
                            return clean_address(text)
                except:
                    continue
            
            driver.quit()
            
        except Exception as e:
            logger.debug(f"Selenium æå–åœ°å€å¤±æ•—: {e}")
        
        return None
        
    except Exception as e:
        logger.error(f"å¾ Maps URL æå–åœ°å€å¤±æ•—: {e}")
        return None

def parse_google_maps_url(url: str) -> Optional[Dict[str, Any]]:
    """
    è§£æ Google Maps URL æå–é¤å»³è³‡è¨Š
    :param url: Google Maps URL
    :return: é¤å»³è³‡è¨Šå­—å…¸æˆ– None
    """
    try:
        # è™•ç†çŸ­ç¶²å€å±•é–‹
        if 'maps.app.goo.gl' in url or 'goo.gl' in url:
            session = create_session()
            response = session.get(url, allow_redirects=True, timeout=10)
            url = response.url
        
        # è§£æä¸åŒæ ¼å¼çš„ Google Maps URL
        restaurant_info = {
            'name': None,
            'address': None,
            'maps_url': url,
            'latitude': None,
            'longitude': None,
            'rating': None,
            'price_level': None
        }
        
        # å¾ URL åƒæ•¸æå–è³‡è¨Š
        parsed = urlparse(url)
        query_params = parse_qs(parsed.query)
        
        # æå–åº§æ¨™
        if '/place/' in url:
            # æ ¼å¼: maps.google.com/maps/place/é¤å»³å/@ç·¯åº¦,ç¶“åº¦,ç¸®æ”¾z
            match = re.search(r'/@(-?\d+\.\d+),(-?\d+\.\d+)', url)
            if match:
                restaurant_info['latitude'] = float(match.group(1))
                restaurant_info['longitude'] = float(match.group(2))
            
            # æå–é¤å»³åç¨±
            place_match = re.search(r'/place/([^/@]+)', url)
            if place_match:
                restaurant_info['name'] = unquote(place_match.group(1)).replace('+', ' ')
        
        # å˜—è©¦å¾ URL æŸ¥è©¢åƒæ•¸æå–
        if 'q' in query_params:
            restaurant_info['name'] = query_params['q'][0]
        
        return restaurant_info
        
    except Exception as e:
        print(f"[URLè§£æ] å¤±æ•—: {e}")
        return None

def search_google_maps_web(keyword: str, location: str = "å°ç£") -> List[Dict[str, Any]]:
    """
    ä½¿ç”¨ç¶²é æœå°‹ Google Maps é¤å»³
    :param keyword: æœå°‹é—œéµå­—
    :param location: åœ°å€é™åˆ¶
    :return: é¤å»³è³‡è¨Šåˆ—è¡¨
    """
    try:
        session = create_session()
        
        # æ§‹å»ºæœå°‹ URL
        search_query = f"{keyword} é¤å»³ {location}"
        encoded_query = quote(search_query)
        search_url = f"https://www.google.com/search?q={encoded_query}"
        
        print(f"[WebSearch] æœå°‹: {search_query}")
        
        # ç™¼é€è«‹æ±‚
        response = session.get(search_url, timeout=15)
        response.raise_for_status()
        
        # è§£æ HTML
        soup = BeautifulSoup(response.text, 'html.parser')
        restaurants = []
        
        # å°‹æ‰¾ Google Maps é€£çµ
        links = soup.find_all('a', href=True)
        for link in links:
            href = link.get('href')
            if href and ('maps.google' in href or 'maps.app.goo.gl' in href):
                # æ¸…ç† URL
                if href.startswith('/url?'):
                    url_param = parse_qs(urlparse(href).query).get('url', [None])[0]
                    if url_param:
                        href = url_param
                
                # è§£æé¤å»³è³‡è¨Š
                restaurant_info = parse_google_maps_url(href)
                if restaurant_info and restaurant_info.get('name'):
                    # é¿å…é‡è¤‡
                    if not any(r['name'] == restaurant_info['name'] for r in restaurants):
                        restaurants.append(restaurant_info)
                        if len(restaurants) >= 10:  # é™åˆ¶çµæœæ•¸é‡
                            break
        
        return restaurants
        
    except Exception as e:
        print(f"[WebSearch] æœå°‹å¤±æ•—: {e}")
        return []

def search_duckduckgo(keyword: str, location: str = "å°ç£") -> List[Dict[str, Any]]:
    """
    ä½¿ç”¨ DuckDuckGo æœå°‹é¤å»³ï¼ˆå‚™ç”¨æ–¹æ¡ˆï¼‰
    :param keyword: æœå°‹é—œéµå­—
    :param location: åœ°å€é™åˆ¶
    :return: é¤å»³è³‡è¨Šåˆ—è¡¨
    """
    try:
        session = create_session()
        
        search_query = f"{keyword} é¤å»³ {location} site:maps.google.com"
        encoded_query = quote(search_query)
        search_url = f"https://duckduckgo.com/html/?q={encoded_query}"
        
        print(f"[DuckDuckGo] æœå°‹: {search_query}")
        
        response = session.get(search_url, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        restaurants = []
        
        # å°‹æ‰¾æœå°‹çµæœ
        results = soup.find_all('a', class_='result__a')
        for result in results:
            href = result.get('href')
            if href and 'maps.google' in href:
                restaurant_info = parse_google_maps_url(href)
                if restaurant_info and restaurant_info.get('name'):
                    restaurants.append(restaurant_info)
                    if len(restaurants) >= 5:
                        break
        
        return restaurants
        
    except Exception as e:
        print(f"[DuckDuckGo] æœå°‹å¤±æ•—: {e}")
        return []

def calculate_distance(user_coords: Tuple[float, float], restaurant_coords: Tuple[float, float]) -> float:
    """
    è¨ˆç®—å…©é»é–“è·é›¢
    :param user_coords: ä½¿ç”¨è€…åº§æ¨™ (lat, lon)
    :param restaurant_coords: é¤å»³åº§æ¨™ (lat, lon)
    :return: è·é›¢ï¼ˆå…¬é‡Œï¼‰
    """
    try:
        distance = geodesic(user_coords, restaurant_coords).kilometers
        return round(distance, 2)
    except Exception:
        return None

def search_restaurants_parallel(keyword: str, location_info: Optional[Dict] = None, max_results: int = 10) -> List[Dict[str, Any]]:
    """
    ä¸¦è¡Œæœå°‹é¤å»³ - å¤šå·¥è™•ç†å„ªåŒ–ç‰ˆæœ¬
    ä½¿ç”¨ç€è¦½å™¨æ± å’Œå¤šåŸ·è¡Œç·’ä¸¦è¡Œæœå°‹ï¼Œå¤§å¹…æå‡æœå°‹é€Ÿåº¦
    
    :param keyword: æœå°‹é—œéµå­—
    :param location_info: ä½ç½®è³‡è¨Š
    :param max_results: æœ€å¤§çµæœæ•¸
    :return: é¤å»³è³‡è¨Šåˆ—è¡¨
    """
    
    # æª¢æŸ¥å¿«å–
    cached_results = search_cache.get(keyword, location_info)
    if cached_results:
        logger.info(f"ğŸ“¦ ä½¿ç”¨å¿«å–çµæœï¼Œé—œéµå­—: {keyword}")
        return cached_results[:max_results]
    
    logger.info(f"ğŸš€ é–‹å§‹ä¸¦è¡Œæœå°‹é¤å»³: {keyword}")
    start_time = time.time()
    
    # æ§‹å»ºæœå°‹æŸ¥è©¢
    if location_info and location_info.get('address'):
        search_query = f"{location_info['address']} {keyword} é¤å»³"
    else:
        search_query = f"{keyword} é¤å»³ å°ç£"
    
    encoded_query = quote(search_query)
    
    # ç²¾ç°¡æœå°‹ç­–ç•¥ - åªç”¨æœ€æœ‰æ•ˆçš„ä¸€ç¨®
    search_strategies = [
        {
            'name': 'Mapsç›´æ¥æœå°‹',
            'url': f"https://www.google.com/maps/search/{encoded_query}/@25.0478,121.5318,12z",
            'priority': 1
        }
    ]
    
    all_restaurants = []
    
    # ä½¿ç”¨ ThreadPoolExecutor ä¸¦è¡ŒåŸ·è¡Œæœå°‹ç­–ç•¥
    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
        # æäº¤æ‰€æœ‰æœå°‹ä»»å‹™
        future_to_strategy = {
            executor.submit(execute_search_strategy_with_pool, strategy, location_info, keyword): strategy 
            for strategy in search_strategies
        }
        
        # æ”¶é›†çµæœ
        for future in concurrent.futures.as_completed(future_to_strategy):
            strategy = future_to_strategy[future]
            
            try:
                restaurants = future.result()
                if restaurants:
                    logger.info(f"âœ… {strategy['name']} æ‰¾åˆ° {len(restaurants)} å€‹çµæœ")
                    all_restaurants.extend(restaurants)
                else:
                    logger.warning(f"âŒ {strategy['name']} æœªæ‰¾åˆ°çµæœ")
                    
            except Exception as e:
                logger.error(f"âŒ {strategy['name']} åŸ·è¡Œå¤±æ•—: {e}")
            
            # å¦‚æœå·²ç¶“æœ‰è¶³å¤ çš„çµæœï¼Œå¯ä»¥è€ƒæ…®æå‰çµæŸ
            if len(all_restaurants) >= max_results * 1.5:  # å¤šæ”¶é›†ä¸€äº›ä»¥ä¾¿ç¯©é¸
                logger.info(f"âœ¨ å·²æ”¶é›†è¶³å¤ çµæœ ({len(all_restaurants)})ï¼ŒåŠ é€Ÿå®Œæˆ")
                break
    
    # å»é‡
    unique_restaurants = remove_duplicate_restaurants(all_restaurants)
    
    # å¦‚æœæœ‰ä½ç½®è³‡è¨Šï¼ŒæŒ‰è·é›¢æ’åº
    if location_info and location_info.get('coords'):
        unique_restaurants = sort_restaurants_by_distance(unique_restaurants, location_info['coords'])
    
    # é™åˆ¶çµæœæ•¸é‡
    final_results = unique_restaurants[:max_results]
    
    # å¿«å–çµæœ
    if final_results:
        search_cache.set(keyword, location_info, final_results)
    
    elapsed_time = time.time() - start_time
    logger.info(f"ğŸ‰ ä¸¦è¡Œæœå°‹å®Œæˆï¼æ‰¾åˆ° {len(final_results)} å®¶é¤å»³ï¼Œè€—æ™‚ {elapsed_time:.2f} ç§’")
    
    return final_results

def execute_search_strategy_with_pool(strategy: Dict, location_info: Optional[Dict] = None, keyword: str = "") -> List[Dict[str, Any]]:
    """
    ä½¿ç”¨ç€è¦½å™¨æ± åŸ·è¡Œå–®å€‹æœå°‹ç­–ç•¥
    
    :param strategy: æœå°‹ç­–ç•¥é…ç½®
    :param location_info: ä½ç½®è³‡è¨Š
    :param keyword: æœå°‹é—œéµå­—
    :return: é¤å»³åˆ—è¡¨
    """
    
    restaurants = []
    
    try:
        with browser_pool.get_browser() as driver:
            logger.info(f"ğŸ” åŸ·è¡Œ {strategy['name']}: {strategy['url']}")
            
            # è¨ªå•æœå°‹é é¢
            driver.get(strategy['url'])
            
            # å¤§å¹…ç¸®çŸ­ç­‰å¾…æ™‚é–“
            time.sleep(0.5)  # åªç­‰å¾… 0.5 ç§’
            
            # æª¢æŸ¥æ˜¯å¦è¢«é˜»æ“‹
            if "sorry" in driver.current_url.lower() or "captcha" in driver.page_source.lower():
                logger.warning(f"âŒ {strategy['name']} è¢« Google é˜»æ“‹")
                return restaurants
            
            # å°‹æ‰¾æœå°‹çµæœ
            result_elements = find_search_results(driver)
            
            if not result_elements:
                logger.warning(f"âŒ {strategy['name']} æœªæ‰¾åˆ°çµæœå…ƒç´ ")
                return restaurants
            
            # æå–é¤å»³è³‡è¨Šï¼ˆé™åˆ¶æ•¸é‡é¿å…éè¼‰ï¼‰
            for element in result_elements[:8]:  # æ¸›å°‘åˆ° 8 å€‹
                try:
                    restaurant_info = extract_restaurant_info_minimal(element, location_info)
                    if restaurant_info and restaurant_info.get('name'):
                        # æª¢æŸ¥æ˜¯å¦ç‚ºé¤å»³ç›¸é—œ
                        if is_restaurant_relevant(restaurant_info['name'], keyword):
                            restaurants.append(restaurant_info)
                            logger.debug(f"âœ… æ‰¾åˆ°é¤å»³: {restaurant_info['name']}")
                        
                except Exception as e:
                    logger.debug(f"æå–é¤å»³è³‡è¨Šå¤±æ•—: {e}")
                    continue
            
            logger.info(f"âœ… {strategy['name']} æˆåŠŸæå– {len(restaurants)} å®¶é¤å»³")
            
    except Exception as e:
        logger.error(f"âŒ {strategy['name']} åŸ·è¡Œå¤±æ•—: {e}")
    
    return restaurants

def remove_duplicate_restaurants(restaurants: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    å»é™¤é‡è¤‡çš„é¤å»³
    
    :param restaurants: é¤å»³åˆ—è¡¨
    :return: å»é‡å¾Œçš„é¤å»³åˆ—è¡¨
    """
    
    seen_names = set()
    unique_restaurants = []
    
    for restaurant in restaurants:
        name = restaurant.get('name', '').strip()
        if name and name not in seen_names:
            seen_names.add(name)
            unique_restaurants.append(restaurant)
    
    return unique_restaurants

def sort_restaurants_by_distance(restaurants: List[Dict[str, Any]], user_coords: Tuple[float, float]) -> List[Dict[str, Any]]:
    """
    æŒ‰è·é›¢æ’åºé¤å»³
    
    :param restaurants: é¤å»³åˆ—è¡¨
    :param user_coords: ç”¨æˆ¶åº§æ¨™
    :return: æ’åºå¾Œçš„é¤å»³åˆ—è¡¨
    """
    
    def get_distance_key(restaurant):
        distance = restaurant.get('distance_km')
        return distance if distance is not None else float('inf')
    
    return sorted(restaurants, key=get_distance_key)

def extract_restaurant_info_minimal(element, location_info: Optional[Dict] = None) -> Optional[Dict[str, Any]]:
    """
    æœ€ç²¾ç°¡çš„é¤å»³è³‡è¨Šæå– - åªç²å–åç¨±å’ŒåŸºæœ¬è³‡è¨Š
    
    :param element: æœå°‹çµæœå…ƒç´ 
    :param location_info: ä½ç½®è³‡è¨Š
    :return: é¤å»³è³‡è¨Šå­—å…¸
    """
    
    restaurant_info = {
        'name': '',
        'address': '',
        'rating': None,
        'distance_km': 3.0  # é è¨­è·é›¢
    }
    
    try:
        # åªæå–åç¨± - ä½¿ç”¨æœ€å¿«çš„é¸æ“‡å™¨
        name_selectors = ["span.OSrXXb", "h3.LC20lb", "div.qBF1Pd"]
        
        for selector in name_selectors:
            try:
                name_element = element.find_element(By.CSS_SELECTOR, selector)
                name = name_element.text.strip()
                if name and len(name) > 1:
                    restaurant_info['name'] = name
                    break
            except:
                continue
        
        if not restaurant_info['name']:
            return None
        
        # å¿«é€Ÿæå–è©•åˆ† (å¯é¸)
        try:
            rating_element = element.find_element(By.CSS_SELECTOR, "span.yi40Hd")
            rating_text = rating_element.text.strip()
            rating_match = re.search(r'(\d+\.?\d*)', rating_text)
            if rating_match:
                restaurant_info['rating'] = float(rating_match.group(1))
        except:
            pass
        
        return restaurant_info
        
    except Exception as e:
        return None

def search_restaurants_selenium(keyword: str, location_info: Optional[Dict] = None, max_results: int = 10) -> List[Dict[str, Any]]:
    """
    ä½¿ç”¨ Selenium æœå°‹ Google Maps é¤å»³
    :param keyword: æœå°‹é—œéµå­—ï¼ˆå¦‚ï¼šç¾Šè‚‰ã€ç«é‹ã€ç‡’çƒ¤ï¼‰
    :param location_info: ä½ç½®è³‡è¨Š {'coords': (lat, lng), 'address': 'address_string'}
    :param max_results: æœ€å¤§çµæœæ•¸
    :return: é¤å»³è³‡è¨Šåˆ—è¡¨
    """
    driver = None
    try:
        logger.info(f"é–‹å§‹æœå°‹é¤å»³: {keyword}")
        
        # å»ºç«‹ç€è¦½å™¨
        driver = create_chrome_driver(headless=True)
        
        # æ§‹å»ºæœå°‹æŸ¥è©¢
        if location_info and location_info.get('address'):
            search_query = f"{location_info['address']} {keyword} é¤å»³"
        else:
            search_query = f"{keyword} é¤å»³ å°ç£"
        
        # å»ºç«‹ Google Local Search URL - æ”¹é€²ç‰ˆï¼Œæ¸›å°‘è¢«åµæ¸¬
        encoded_query = quote(search_query)
        
        # å˜—è©¦ä¸åŒçš„æœå°‹ç­–ç•¥
        search_strategies = [
            f"https://www.google.com/maps/search/{encoded_query}/@25.0478,121.5318,12z",  # Maps ç›´æ¥æœå°‹
            f"https://www.google.com/search?tbm=lcl&q={encoded_query}&hl=zh-TW",  # Local æœå°‹
            f"https://www.google.com/search?q={encoded_query}+åœ°å€&hl=zh-TW"  # ä¸€èˆ¬æœå°‹åŠ ä¸Šåœ°å€é—œéµå­—
        ]
        
        result_elements = []
        for strategy_index, search_url in enumerate(search_strategies):
            logger.info(f"å˜—è©¦æœå°‹ç­–ç•¥ {strategy_index + 1}: {search_url}")
            
            try:
                # è¨ªå•æœå°‹é é¢
                driver.get(search_url)
                time.sleep(random.uniform(3, 6))  # éš¨æ©Ÿç­‰å¾…æ™‚é–“
                
                # æª¢æŸ¥æ˜¯å¦è¢« Google é˜»æ“‹
                if "sorry" in driver.current_url.lower() or "captcha" in driver.page_source.lower():
                    logger.warning(f"ç­–ç•¥ {strategy_index + 1} è¢« Google é˜»æ“‹ï¼Œå˜—è©¦ä¸‹ä¸€å€‹ç­–ç•¥")
                    continue
                
                # å˜—è©¦å°‹æ‰¾æœå°‹çµæœ
                result_elements = find_search_results(driver)
                if result_elements:
                    logger.info(f"ç­–ç•¥ {strategy_index + 1} æ‰¾åˆ° {len(result_elements)} å€‹çµæœ")
                    break
                else:
                    logger.warning(f"ç­–ç•¥ {strategy_index + 1} æœªæ‰¾åˆ°çµæœ")
                    
            except Exception as e:
                logger.warning(f"æœå°‹ç­–ç•¥ {strategy_index + 1} å¤±æ•—: {e}")
                continue
        
        if not result_elements:
            logger.warning("æ‰€æœ‰æœå°‹ç­–ç•¥éƒ½å¤±æ•—ï¼Œç„¡æ³•æ‰¾åˆ°æœå°‹çµæœ")
            return []
        
        restaurants = []
        # æå–é¤å»³è³‡è¨Š
        for i, element in enumerate(result_elements[:max_results]):
            try:
                restaurant_info = extract_restaurant_info_minimal(element, location_info)
                if restaurant_info and restaurant_info.get('name'):
                    # æª¢æŸ¥æ˜¯å¦ç‚ºé¤å»³ç›¸é—œ
                    if is_restaurant_relevant(restaurant_info['name'], keyword):
                        restaurants.append(restaurant_info)
                        logger.info(f"æ‰¾åˆ°é¤å»³: {restaurant_info['name']}")
                
            except Exception as e:
                logger.error(f"æå–ç¬¬ {i+1} å€‹çµæœå¤±æ•—: {e}")
                continue
        
        logger.info(f"ç¸½å…±æ‰¾åˆ° {len(restaurants)} å®¶é¤å»³")
        return restaurants
        
    except Exception as e:
        logger.error(f"Selenium æœå°‹å¤±æ•—: {e}")
        return []
        
    finally:
        if driver:
            driver.quit()

def find_search_results(driver) -> List:
    """
    åœ¨æœå°‹é é¢ä¸­å°‹æ‰¾çµæœå…ƒç´ 
    :param driver: WebDriver å¯¦ä¾‹
    :return: æœå°‹çµæœå…ƒç´ åˆ—è¡¨
    """
    # å˜—è©¦å¤šç¨®å…ƒç´ é¸æ“‡å™¨ç­–ç•¥ - æ›´æ–°çš„ Google çµæ§‹
    selectors = [
        "div.VkpGBb",  # æ–°ç‰ˆ Google Local çµæœå®¹å™¨
        "div.dbg0pd",  # å¦ä¸€ç¨®çµæœå®¹å™¨
        "div.rllt__details",  # æœ¬åœ°æœå°‹çµæœè©³æƒ…
        "div.UaQhfb",  # åœ°åœ–æœå°‹çµæœ
        "div[data-ved]",  # é€šç”¨çš„æœ‰ data-ved å±¬æ€§çš„å®¹å™¨
        ".g",  # å‚³çµ±æœå°‹çµæœ
        "div.Nv2PK",  # æ–°çš„åœ°æ–¹æœå°‹çµæœ
        "div.P7xzyf",  # å¦ä¸€ç¨®åœ°æ–¹çµæœæ ¼å¼
        "article",  # HTML5 æ–‡ç« å…ƒç´ 
        "div[role='article']",  # èªç¾©åŒ–æœå°‹çµæœ
        "div.tF2Cxc",  # æ–°ç‰ˆæœå°‹çµæœå®¹å™¨
        "div.MjjYud"  # å¦ä¸€ç¨®æ–°ç‰ˆå®¹å™¨
    ]
    
    result_elements = []
    for selector in selectors:
        try:
            elements = driver.find_elements(By.CSS_SELECTOR, selector)
            if elements:
                logger.info(f"ä½¿ç”¨é¸æ“‡å™¨ {selector} æ‰¾åˆ° {len(elements)} å€‹å…ƒç´ ")
                result_elements = elements
                break
        except Exception:
            continue
    
    return result_elements

def extract_restaurant_info_from_element_improved(element, location_info: Optional[Dict] = None, driver=None) -> Optional[Dict[str, Any]]:
    """
    æ”¹é€²ç‰ˆé¤å»³è³‡è¨Šæå–å‡½æ•¸ - ç¾åœ¨ç›´æ¥èª¿ç”¨ç²¾ç°¡ç‰ˆæœ¬
    :param element: Selenium WebElement
    :param location_info: ä½¿ç”¨è€…ä½ç½®è³‡è¨Š
    :param driver: WebDriver å¯¦ä¾‹
    :return: é¤å»³è³‡è¨Šå­—å…¸
    """
    # ç›´æ¥èª¿ç”¨ç²¾ç°¡ç‰ˆæœ¬ï¼Œå¤§å¹…æå‡é€Ÿåº¦
    return extract_restaurant_info_minimal(element, location_info)

def is_restaurant_relevant(restaurant_name: str, keyword: str) -> bool:
    """
    æª¢æŸ¥é¤å»³æ˜¯å¦èˆ‡æœå°‹é—œéµå­—ç›¸é—œ
    :param restaurant_name: é¤å»³åç¨±
    :param keyword: æœå°‹é—œéµå­—
    :return: æ˜¯å¦ç›¸é—œ
    """
    # å¦‚æœé¤å»³åç¨±ç‚ºç©ºæˆ–å¤ªçŸ­ï¼Œæš«æ™‚æ¥å—ï¼ˆå¯¬é¬†ç­–ç•¥ï¼‰
    if not restaurant_name or len(restaurant_name) < 2:
        return True  # å¯¬é¬†æ¥å—ï¼Œè®“å…¶ä»–é©—è­‰ä¾†ç¯©é¸
    
    # é¤å»³ç›¸é—œé—œéµå­—
    restaurant_keywords = [
        'é¤å»³', 'é£¯åº—', 'é£Ÿå ‚', 'å°åƒ', 'ç¾é£Ÿ', 'æ–™ç†', 
        'ç«é‹', 'ç‡’çƒ¤', 'æ‹‰éºµ', 'ç¾©å¤§åˆ©éºµ', 'ç‰›æ’', 'å£½å¸',
        'ç¾Šè‚‰', 'ç‰›è‚‰', 'è±¬è‚‰', 'é›è‚‰', 'æµ·é®®', 'ç´ é£Ÿ',
        'æ—©é¤', 'åˆé¤', 'æ™šé¤', 'å®µå¤œ', 'å’–å•¡', 'èŒ¶',
        'ä¸­å¼', 'è¥¿å¼', 'æ—¥å¼', 'éŸ“å¼', 'æ³°å¼', 'ç¾©å¼',
        'åº—', 'é¤¨', 'åŠ', 'è»’', 'é–£', 'æ¨“', 'å±‹'  # å¢åŠ å¸¸è¦‹åº—å®¶å¾Œç¶´
    ]
    
    # æª¢æŸ¥é¤å»³åç¨±æ˜¯å¦åŒ…å«é¤å»³ç›¸é—œå­—è©
    name_lower = restaurant_name.lower()
    keyword_lower = keyword.lower()
    
    # å¦‚æœé¤å»³åç¨±åŒ…å«æœå°‹é—œéµå­—
    if keyword_lower in name_lower:
        return True
    
    # å¦‚æœé¤å»³åç¨±åŒ…å«é¤å»³ç›¸é—œé—œéµå­—
    if any(kw in restaurant_name for kw in restaurant_keywords):
        return True
    
    # æ’é™¤æ˜é¡¯éé¤å»³çš„çµæœ
    exclude_keywords = ['éŠ€è¡Œ', 'é†«é™¢', 'å­¸æ ¡', 'å…¬å¸', 'æ”¿åºœ', 'æ©Ÿé—œ', 'åœè»Šå ´', 'åŠ æ²¹ç«™', 'ä¾¿åˆ©å•†åº—', 'è¶…å¸‚']
    if any(kw in restaurant_name for kw in exclude_keywords):
        return False
    
    # å¯¬é¬†ç­–ç•¥ï¼šå¦‚æœä¸æ˜¯æ˜é¡¯æ’é™¤çš„é¡å‹ï¼Œå°±æ¥å—
    return True
def search_restaurants(keyword: str, user_address: Optional[str] = None, max_results: int = 10) -> List[Dict[str, Any]]:
    """
    æœå°‹é¤å»³ä¸»å‡½æ•¸ï¼ˆæ”¯æ´å¤šç¨®è¼¸å…¥æ ¼å¼ï¼‰
    :param keyword: æœå°‹é—œéµå­—
    :param user_address: ä½¿ç”¨è€…åœ°å€æˆ– Google Maps çŸ­ç¶²å€
    :param max_results: æœ€å¤§çµæœæ•¸
    :return: é¤å»³è³‡è¨Šåˆ—è¡¨
    """
    location_info = None
    
    # è™•ç†ä½¿ç”¨è€…ä½ç½®è³‡è¨Š
    if user_address:
        if user_address.startswith('http') and ('maps.app.goo.gl' in user_address or 'maps.google' in user_address or 'g.co/kgs/' in user_address or 'goo.gl' in user_address):
            # è™•ç† Google Maps çŸ­ç¶²å€
            logger.info(f"è™•ç† Google Maps URL: {user_address}")
            location_data = extract_location_from_url(user_address)
            if location_data:
                lat, lng, place_name = location_data
                location_info = {
                    'coords': (lat, lng),
                    'address': place_name or user_address
                }
                logger.info(f"å¾ URL æå–ä½ç½®: {place_name} ({lat}, {lng})")
        else:
            # è™•ç†ä¸€èˆ¬åœ°å€
            logger.info(f"è™•ç†åœ°å€: {user_address}")
            coords = geocode_address(user_address)
            if coords:
                location_info = {
                    'coords': coords,
                    'address': user_address
                }
                logger.info(f"åœ°å€åº§æ¨™: {coords}")
            else:
                # å³ä½¿ç„¡æ³•ç²å¾—åº§æ¨™ï¼Œä¹Ÿä¿ç•™åœ°å€ç”¨æ–¼æœå°‹
                location_info = {
                    'coords': None,
                    'address': user_address
                }
                logger.warning(f"ç„¡æ³•ç²å¾—åœ°å€åº§æ¨™ï¼Œåƒ…ç”¨æ–¼æœå°‹: {user_address}")
    
    # ä½¿ç”¨ä¸¦è¡Œæœå°‹ï¼ˆå„ªå…ˆï¼‰æˆ–å‚³çµ± Selenium æœå°‹
    try:
        results = search_restaurants_parallel(keyword, location_info, max_results)
        if results:
            logger.info(f"ğŸš€ ä¸¦è¡Œæœå°‹æˆåŠŸæ‰¾åˆ° {len(results)} å€‹çµæœ")
        else:
            logger.info("ä¸¦è¡Œæœå°‹ç„¡çµæœï¼Œå˜—è©¦å‚³çµ± Selenium æœå°‹")
            results = search_restaurants_selenium(keyword, location_info, max_results)
    except Exception as e:
        logger.warning(f"ä¸¦è¡Œæœå°‹å¤±æ•—: {e}ï¼Œä½¿ç”¨å‚³çµ±æœå°‹")
        results = search_restaurants_selenium(keyword, location_info, max_results)
    
    # å¦‚æœ Selenium å¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆ
    if not results:
        logger.info("Selenium æœå°‹ç„¡çµæœï¼Œä½¿ç”¨å‚™ç”¨æœå°‹æ–¹æ¡ˆ")
        results = search_google_maps_web_fallback(keyword, location_info)
    
    # ç‚ºæ¯å€‹çµæœé©—è­‰ä¸¦å„ªåŒ–URL
    for restaurant in results:
        if restaurant.get('name'):
            reliable_url = get_reliable_maps_url(restaurant)
            restaurant['maps_url'] = reliable_url
            logger.debug(f"ç‚º {restaurant['name']} å„ªåŒ–URL: {reliable_url[:50]}...")
    
    return results

def search_google_maps_web_fallback(keyword: str, location_info: Optional[Dict] = None) -> List[Dict[str, Any]]:
    """
    å‚™ç”¨æœå°‹æ–¹æ¡ˆï¼ˆä½¿ç”¨ requestsï¼‰
    """
    try:
        location_str = "å°ç£"
        if location_info and location_info.get('address'):
            location_str = location_info['address']
        
        return search_google_maps_web(keyword, location_str)
    except Exception as e:
        logger.error(f"å‚™ç”¨æœå°‹å¤±æ•—: {e}")
        return []

# æ¸¬è©¦å‡½æ•¸æ›´æ–°
def test_search_cases():
    """æ¸¬è©¦å„ç¨®æœå°‹æ¡ˆä¾‹"""
    test_cases = [
        # (user_address, keyword, èªªæ˜)
        ("https://maps.app.goo.gl/qmnmsH1EwrYnYsCF6", "ç¾Šè‚‰", "çŸ­ç¶²å€+ç¾Šè‚‰"),
        ("243æ–°åŒ—å¸‚æ³°å±±å€æ˜å¿—è·¯äºŒæ®µ210è™Ÿ", "ç«é‹", "æ³°å±±ç«é‹"),
        ("å½°åŒ–å¤§ä½›", "ç‡’çƒ¤", "å½°åŒ–å¤§ä½›ç‡’çƒ¤"),
        ("å°åŒ—ä¸­å±±å€", "ç¾©å¤§åˆ©éºµ", "ä¸­å±±å€ç¾©å¤§åˆ©éºµ(ç„¡è©³ç´°åœ°å€)")
    ]
    
    for idx, (addr, kw, desc) in enumerate(test_cases, 1):
        print(f"\n=== æ¸¬è©¦æ¡ˆä¾‹ {idx}: {desc} ===")
        print(f"ä½ç½®: {addr}")
        print(f"é—œéµå­—: {kw}")
        print("-" * 50)
        
        try:
            results = search_restaurants(keyword=kw, user_address=addr, max_results=5)
            
            if not results:
                print("âŒ æ²’æœ‰æ‰¾åˆ°ç›¸é—œé¤å»³ï¼")
            else:
                print(f"âœ… æ‰¾åˆ° {len(results)} å®¶é¤å»³:")
                for i, restaurant in enumerate(results, 1):
                    print(f"\n{i}. ğŸ½ï¸ {restaurant['name']}")
                    print(f"   ğŸ“ åœ°å€: {restaurant.get('address', 'æœªæä¾›')}")
                    if restaurant.get('distance_km') is not None:
                        print(f"   ğŸ“ è·é›¢: {restaurant['distance_km']} å…¬é‡Œ")
                    if restaurant.get('rating'):
                        print(f"   â­ è©•åˆ†: {restaurant['rating']}")
                    if restaurant.get('price_level'):
                        print(f"   ğŸ’° åƒ¹æ ¼: {restaurant['price_level']}")
                    if restaurant.get('maps_url'):
                        print(f"   ğŸ”— Google Maps: {restaurant['maps_url']}")
            
        except Exception as e:
            print(f"âŒ æœå°‹å¤±æ•—: {e}")
        
        print("\n" + "="*80)
        time.sleep(2)  # é¿å…è«‹æ±‚éå¿«

def generate_fallback_maps_url(restaurant_name: str, address: str = "") -> str:
    """
    ç”Ÿæˆå¾Œå‚™çš„Google Mapsæœå°‹é€£çµ
    ä½¿ç”¨å›ºå®šæ ¼å¼ç¢ºä¿é€£çµå§‹çµ‚å¯ç”¨
    
    :param restaurant_name: é¤å»³åç¨±
    :param address: åœ°å€ï¼ˆå¯é¸ï¼‰
    :return: Google Mapsæœå°‹URL
    """
    try:
        encoded_name = quote(restaurant_name)
        if address:
            # æ¸…ç†åœ°å€ï¼Œåªä¿ç•™ä¸»è¦éƒ¨åˆ†
            clean_address = address.split(',')[0].strip() if ',' in address else address.strip()
            encoded_address = quote(clean_address)
            return f"https://www.google.com/maps/search/{encoded_name}+{encoded_address}"
        else:
            return f"https://www.google.com/maps/search/{encoded_name}"
    except Exception as e:
        logger.warning(f"ç”Ÿæˆå¾Œå‚™URLå¤±æ•—: {e}")
        return f"https://www.google.com/maps/search/{restaurant_name}"

def validate_maps_url(url: str) -> bool:
    """
    é©—è­‰Google Maps URLæ˜¯å¦å¯ç”¨
    
    :param url: è¦é©—è­‰çš„URL
    :return: True if URL is accessible, False otherwise
    """
    if not url:
        return False
        
    try:
        # è·³éSSLé©—è­‰å’Œè­¦å‘Š
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
        response = requests.get(
            url, 
            headers={'User-Agent': random.choice(USER_AGENTS)}, 
            timeout=10,
            verify=False,
            allow_redirects=True
        )
        return response.status_code == 200
    except Exception:
        return False

def get_reliable_maps_url(restaurant_info: dict) -> str:
    """
    ç²å–å¯é çš„Google Mapsé€£çµ
    å„ªå…ˆé †åºï¼š
    1. ç³»çµ±æå–çš„åŸå§‹URLï¼ˆå¦‚æœå¯ç”¨ï¼‰
    2. ç°¡åŒ–æœå°‹URL + åœ°å€
    3. ç´”é¤å»³åç¨±æœå°‹URL
    
    :param restaurant_info: é¤å»³è³‡è¨Šå­—å…¸
    :return: å¯é çš„Google Maps URL
    """
    name = restaurant_info.get('name', '')
    address = restaurant_info.get('address', '').split(',')[0] if restaurant_info.get('address') else ''
    original_url = restaurant_info.get('maps_url', '')
    
    # æ¸¬è©¦åŸå§‹URLï¼ˆå¿«é€Ÿé©—è­‰ï¼Œä¸éœ€è¦å¯¦éš›è«‹æ±‚ï¼‰
    if original_url and '/maps/place/' in original_url and '!' in original_url:
        # åŸå§‹URLçœ‹èµ·ä¾†æ˜¯æ­£ç¢ºçš„é¤å»³æ ¼å¼
        return original_url
    
    # å¾Œå‚™æ–¹æ¡ˆ1ï¼šé¤å»³åç¨± + åœ°å€
    if name and address:
        fallback_url = generate_fallback_maps_url(name, address)
        return fallback_url
    
    # å¾Œå‚™æ–¹æ¡ˆ2ï¼šç´”é¤å»³åç¨±
    if name:
        simple_url = generate_fallback_maps_url(name)
        return simple_url
    
    # æœ€çµ‚å¾Œå‚™ï¼šåŸå§‹URLï¼ˆå³ä½¿å¯èƒ½ä¸å¯ç”¨ï¼‰
    return original_url or "https://www.google.com/maps"

def get_restaurant_details(maps_url: str) -> Optional[Dict[str, Any]]:
    """
    ç²å–é¤å»³è©³ç´°è³‡è¨Š
    :param maps_url: Google Maps URL
    :return: è©³ç´°é¤å»³è³‡è¨Š
    """
    try:
        session = create_session()
        response = session.get(maps_url, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # æå–é¤å»³è©³ç´°è³‡è¨Š
        details = {
            'name': None,
            'rating': None,
            'review_count': None,
            'price_level': None,
            'phone': None,
            'website': None,
            'hours': None,
            'address': None
        }
        
        # é€™è£¡å¯ä»¥æ ¹æ“š Google Maps çš„ HTML çµæ§‹æå–æ›´å¤šè©³ç´°è³‡è¨Š
        # ç”±æ–¼ Google Maps ä½¿ç”¨å‹•æ…‹è¼‰å…¥ï¼Œå®Œæ•´å¯¦ä½œéœ€è¦ Selenium
        
        return details
        
    except Exception as e:
        print(f"[è©³ç´°è³‡è¨Š] ç²å–å¤±æ•—: {e}")
        return None

# æ¸¬è©¦å‡½æ•¸
def test_search():
    """æ¸¬è©¦æœå°‹åŠŸèƒ½"""
    print("ğŸš€ é–‹å§‹æ¸¬è©¦ Google Maps é¤å»³æœå°‹åŠŸèƒ½")
    print("=" * 80)
    test_search_cases()

if __name__ == "__main__":
    test_search()

# æ¸…ç†å‡½æ•¸
def cleanup_resources():
    """æ¸…ç†ç³»çµ±è³‡æº"""
    try:
        browser_pool.close_all()
        logger.info("âœ… è³‡æºæ¸…ç†å®Œæˆ")
    except Exception as e:
        logger.error(f"âŒ è³‡æºæ¸…ç†å¤±æ•—: {e}")

# ç¢ºä¿ç¨‹åºé€€å‡ºæ™‚æ¸…ç†è³‡æº
import atexit
atexit.register(cleanup_resources)
